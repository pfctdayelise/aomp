{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a data-flickr-embed=\"true\"  href=\"https://www.flickr.com/photos/pfctdayelise/371603584\" title=\"Sania Mirza\"><img src=\"https://farm1.staticflickr.com/136/371603584_b2127a2671_n.jpg\" width=\"198\" height=\"320\" alt=\"Sania Mirza\" align=\"left\" style=\"padding-right:30px;\"></a><script async src=\"//embedr.flickr.com/assets/client-code.js\" charset=\"utf-8\"></script> \n",
    "In 2006 and 2007 I went to the Australian Open to watch the tennis, and source freely-licensed photographs of tennis players for Wikipedia. I took around [100 photos](https://en.wikipedia.org/wiki/User:Pfctdayelise/Bragsheet#Tennis_photos), and happily many of them survive in Wikipedia articles [to](https://en.wikipedia.org/wiki/Tim_Henman) [this](https://en.wikipedia.org/wiki/Anne_Kremer) [day](https://en.wikipedia.org/wiki/Cyril_Saulnier). \n",
    "\n",
    "Seeing your images on articles is a pretty feel-good way of [contributing](https://en.wikipedia.org/wiki/Wikipedia:Ten_things_you_may_not_know_about_images_on_Wikipedia) to Wikipedia. So I am thinking about going again this year (the [Open](http://www.ausopen.com/index.html) started today), but the scattershot approach I used in 2007 isn't going to cut it any more. So I need to figure out, which players don't have _any_ photos on their Wikipedia bio?\n",
    "\n",
    "   * [Who's playing?](#Who%27s-playing?)\n",
    "   * [Using the Wikipedia API](#Using-the-Wikipedia-API)\n",
    "   * [Redirects](#Redirects)\n",
    "   * [Page doesn't exist](#Page-doesn%27t-exist)\n",
    "   * [Disambiguation pages](#Disambiguation-pages)\n",
    "   * [hasImage](#hasImage)\n",
    "   * [Full results](#Full-results)\n",
    "\n",
    "_Also this photo of Sania Mirza is the third most popular image I have on Flickr - no idea why._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who's playing?\n",
    "\n",
    "The official website has a [list of players](http://www.ausopen.com/en_AU/players/profiles.html). That's pretty quick to manually copy into a text file and delete a few stray lines.\n",
    "\n",
    "There are 546 players, so I'm going to work with a shorter sample until I get things vaguely working, to speed up development and avoid hitting the API unnecessarily often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Wikipedia API\n",
    "\n",
    "Actually there is no Wikipedia API. But there is a [MediaWiki API](https://www.mediawiki.org/wiki/API:Main_page). It's very powerful, too - all kinds of [bots](http://www.technologyreview.com/view/524751/the-shadowy-world-of-wikipedias-editing-bots/) are powered by it. And there is a good Python client library, called [mwclient](https://github.com/mwclient/mwclient). OK, so I just want something a bit like this \\*cracks knuckles\\* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # sampleplayers.txt\n",
    "    \n",
    "    Baghdatis, Marcos\n",
    "    Bai, Yan\n",
    "    Baker, Brian\n",
    "    Barrere, Gregoire\n",
    "    Basic, Mirza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has image: []\n",
      "Needs image: ['Baghdatis, Marcos\\n', 'Bai, Yan\\n', 'Baker, Brian\\n', 'Barrere, Gregoire\\n', 'Basic, Mirza\\n']\n"
     ]
    }
   ],
   "source": [
    "import mwclient\n",
    "site = mwclient.Site('en.wikipedia.org')\n",
    "\n",
    "PLAYERSFILE = 'sampleplayers.txt'\n",
    "\n",
    "\n",
    "def getPage(name):\n",
    "    return site.Pages[name]\n",
    "\n",
    "\n",
    "def hasImage(page):\n",
    "    # TODO\n",
    "    return False\n",
    "\n",
    "\n",
    "hasimage = []\n",
    "needsimage = []\n",
    "\n",
    "with open(PLAYERSFILE) as players:\n",
    "    for player in players:\n",
    "        page = getPage(player)\n",
    "        if hasImage(page):\n",
    "            hasimage.append(player)\n",
    "        else:\n",
    "            needsimage.append(player)\n",
    "            \n",
    "print(\"Has image:\", hasimage)\n",
    "print(\"Needs image:\", needsimage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I'll worry about `hasImage` in a minute. Right now there is a more pressing problem: fixing up the names. I need to get rid of those newlines and make them 'firstname lastname' to match the Wikipedia naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has image: []\n",
      "Needs image: ['Marcos Baghdatis', 'Yan Bai', 'Brian Baker', 'Gregoire Barrere', 'Mirza Basic']\n"
     ]
    }
   ],
   "source": [
    "def normaliseName(name):\n",
    "    last, first = name.strip().split(', ')\n",
    "    return ' '.join([first, last])\n",
    "\n",
    "\n",
    "hasimage = []\n",
    "needsimage = []\n",
    "\n",
    "with open(PLAYERSFILE) as players:\n",
    "    for player in players:\n",
    "        forwardname = normaliseName(player)\n",
    "        page = getPage(forwardname)\n",
    "        if hasImage(page):\n",
    "            hasimage.append(forwardname)\n",
    "        else:\n",
    "            needsimage.append(forwardname)\n",
    "            \n",
    "print(\"Has image:\", hasimage)\n",
    "print(\"Needs image:\", needsimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Maybe now I should verify the pages look like what I think they do..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARCOS BAGHDATIS\n",
      "{{Use dmy dates|date=June 2013}}\n",
      "{{Infobox tennis biography\n",
      "|name= Marcos Baghdatis<br><small>ŒúŒ¨œÅŒ∫ŒøœÇ Œ†Œ±Œ≥Œ¥Œ±œÑŒÆœÇ</small>\n",
      "|image= Marcos Baghdatis Olympics 2012.jpg\n",
      "|country= {{CYP}}\n",
      "|residence= [[Limasso\n",
      "YAN BAI\n",
      "#redirect [[Bai Yan]]\n",
      "BRIAN BAKER\n",
      "'''Brian Baker''' may refer to:\n",
      "\n",
      "* [[Brian Baker (musician)]] (born 1965), American guitarist for punk bands Minor Threat, Dag Nasty, and Bad Religion, among others\n",
      "* [[Brian Baker (actor)]] (born 196\n",
      "GREGOIRE BARRERE\n",
      "\n",
      "MIRZA BASIC\n",
      "#REDIRECT [[Mirza Ba≈°iƒá]]\n",
      "{{R from title without diacritics}}\n"
     ]
    }
   ],
   "source": [
    "with open(PLAYERSFILE) as players:\n",
    "    for player in players:\n",
    "        forwardname = normaliseName(player)\n",
    "        page = getPage(forwardname)\n",
    "        print(forwardname.upper())\n",
    "        print(page.text()[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reveals a few issues I need to deal with before I start looking at images. The [Marcos Baghdatis](https://en.wikipedia.org/wiki/Marcos_Baghdatis) article seems [legit](https://en.wikipedia.org/wiki/Marcos_Baghdatis?action=edit&veswitched=1). Yan Bai and Mirza Basic are redirects. Brian Baker is a disambiguation page, and Gregoire Barrere maybe doesn't have a page yet. üò¢ Can anyone [fix that](https://en.wikipedia.org/wiki/Gr%C3%A9goire_Barr%C3%A8re)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redirects\n",
    "\n",
    "If I type in \"Yan Bai\" at Wikipedia, I get whisked off to https://en.wikipedia.org/wiki/Bai_Yan . There is a visual hint that something happened:\n",
    "\n",
    "<img src=\"blog/redirect.png\" />\n",
    "\n",
    "Happily, the API knows about redirects and can automatically resolve them for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPage(name):\n",
    "    return site.Pages[name].resolve_redirect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAN BAI\n",
      "{{chinese name|[[Bo (Chinese name)|Bai/Bo (Êüè)]]}}\n",
      "{{Infobox tennis biography\n",
      "|name = Bai Yan\n",
      "|image = \n",
      "|country = {{CHN}}<ref name=ATPProfile>{{cite news|title=ATP.com - Yan Bai Profile|url=http://www\n",
      "MIRZA BASIC\n",
      "{{Infobox tennis biography\n",
      "| name                  = Mirza Ba≈°iƒá\n",
      "| image                 = <!-- Commented out because image was deleted: [[File:Mirza-Basic.jpg|200px]] -->\n",
      "| nickname              =\n",
      "| \n"
     ]
    }
   ],
   "source": [
    "for player in ['Yan Bai', 'Mirza Basic']:\n",
    "    page = getPage(player)\n",
    "    print(player.upper())\n",
    "    print(page.text()[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks better! In the second case, the correct name is Mirza Ba≈°iƒá. It's embarrassing that the official Australian Open website can't cope with diacritics tbh.\n",
    "\n",
    "To record the correct name of the page, I can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mirza Ba≈°iƒá'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page doesn't exist\n",
    "\n",
    "Gregoire Barrere (or rather Gr√©goire Barr√®re) doesn't have a page yet. The API also copes with this pretty well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site.Pages['Gregoire Barrere'].exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I update my `getPage` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needs page: ['Gregoire Barrere']\n",
      "Has image: []\n",
      "Needs image: ['Marcos Baghdatis', 'Bai Yan', 'Brian Baker', 'Mirza Ba≈°iƒá']\n"
     ]
    }
   ],
   "source": [
    "def getPage(name):\n",
    "    page = site.Pages[name].resolve_redirect()\n",
    "    if not page.exists:\n",
    "        return\n",
    "    return page\n",
    "\n",
    "\n",
    "needspage = []\n",
    "hasimage = []\n",
    "needsimage = []\n",
    "\n",
    "with open(PLAYERSFILE) as players:\n",
    "    for player in players:\n",
    "        forwardname = normaliseName(player)\n",
    "        page = getPage(forwardname)\n",
    "        if not page:\n",
    "            needspage.append(forwardname)\n",
    "            continue\n",
    "\n",
    "        if hasImage(page):\n",
    "            hasimage.append(page.name)\n",
    "        else:\n",
    "            needsimage.append(page.name)\n",
    "\n",
    "print(\"Needs page:\", needspage)\n",
    "print(\"Has image:\", hasimage)\n",
    "print(\"Needs image:\", needsimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disambiguation pages\n",
    "\n",
    "Disambiguation or \"dab\" pages are what I would call part of the Wikipedia API. They're built on editing community conventions rather than technical capabilities of MediaWiki. But I need to deal with them otherwise the results will be nonsense.\n",
    "\n",
    "So let's look at the full content of the Brian Baker page and see what there is to play with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'''Brian Baker''' may refer to:\n",
      "\n",
      "* [[Brian Baker (musician)]] (born 1965), American guitarist for punk bands Minor Threat, Dag Nasty, and Bad Religion, among others\n",
      "* [[Brian Baker (actor)]] (born 1967), American actor and former Sprint spokesman\n",
      "* [[Brian Baker (tennis)]] (born 1985), American professional tennis player\n",
      "* [[Brian Baker (The Wire)]], police officer on the HBO drama ''The Wire''\n",
      "* [[Brian Baker (diplomat)]] (born 1944), former Canadian diplomat and Ambassador to Denmark\n",
      "* [[Brian Baker (politician)]], American politician and Missouri State Representative\n",
      "* [[Brian Baker (producer)]], American engineer and producer for bands including Blue October\n",
      "* Brian Baker, Australian singer for [[The Makers (Australian band)|The Makers]] and others\n",
      "* [[Brian Baker (runner)]] (born 1970), American track and field athlete and coach\n",
      "* [[Brian Edmund Baker]] (1896‚Äì1979), World War I flying ace\n",
      "\n",
      "==See also==\n",
      "* [[Bryan Baker (disambiguation)]]\n",
      "\n",
      "{{hndis|Baker, Brian}}\n",
      "\n",
      "{{DEFAULTSORT:Baker, Brian}}\n",
      "\n",
      "<!-- HawkEyeBot last run at 14:50:09 (UTC) on 23 Oct, 2012 -->\n"
     ]
    }
   ],
   "source": [
    "page = site.Pages['Brian Baker']\n",
    "print(page.text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm ok...kind of not that useful. If I look at the page on Wikipedia, I can see there is a bit more structure that is not evident in the page wikitext:\n",
    "\n",
    "<img src=\"blog/brianbakerdisambig.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the bottom there is a category which seems pretty definitive in terms of identifying a disambiguation page. Categories _are_ part of the MediaWiki API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category:All disambiguation pages\n",
      "Category:All article disambiguation pages\n",
      "Category:Human name disambiguation pages\n"
     ]
    }
   ],
   "source": [
    "page = site.Pages['Brian Baker']\n",
    "cats = page.categories()\n",
    "for cat in cats:\n",
    "    print(cat['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some bonus categories, because MediaWiki supports [hidden categories](https://www.mediawiki.org/wiki/Help:Categories#Hidden_categories). This is one of those features that you don't need unless your wiki has millions of pages and a crowd of obsessive sorters. If you have your preferences arranged just-so you can actually get these categories to show up.\n",
    "\n",
    "<img src=\"blog/disambighiddencategories.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so... to detect a disambiguation page, I can probably just look for one of these categories. In the API there are two ways to do this - check if the page is in the category, or check if category is attached to the page. Sounds much of a muchness, but the [category All disambiguation pages](https://en.wikipedia.org/wiki/Category:All_disambiguation_pages) has over 265,000 members. So I have a hunch let's not do it that way üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def isDisambiguation(page):\n",
    "    cats = page.categories()\n",
    "    disambigCat = 'Category:All disambiguation pages'\n",
    "    return disambigCat in [cat['title'] for cat in cats]\n",
    "\n",
    "page = site.Pages['Brian Baker']\n",
    "print(isDisambiguation(page))\n",
    "\n",
    "page = site.Pages['Marcos Baghdatis']\n",
    "print(isDisambiguation(page))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Another task is try and resolve the disambiguation page to the correct page, but I'll tackle that later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needs page: ['Gregoire Barrere']\n",
      "Disambig: ['Brian Baker']\n",
      "Has image: []\n",
      "Needs image: ['Marcos Baghdatis', 'Bai Yan', 'Mirza Ba≈°iƒá']\n"
     ]
    }
   ],
   "source": [
    "needspage = []\n",
    "disambigs = []\n",
    "hasimage = []\n",
    "needsimage = []\n",
    "\n",
    "with open(PLAYERSFILE) as players:\n",
    "    for player in players:\n",
    "        forwardname = normaliseName(player)\n",
    "        page = getPage(forwardname)\n",
    "        if not page:\n",
    "            needspage.append(forwardname)\n",
    "            continue\n",
    "\n",
    "        if isDisambiguation(page):\n",
    "            disambigs.append(page.name)\n",
    "        elif hasImage(page):\n",
    "            hasimage.append(page.name)\n",
    "        else:\n",
    "            needsimage.append(page.name)\n",
    "\n",
    "print(\"Needs page:\", needspage)\n",
    "print(\"Disambig:\", disambigs)\n",
    "print(\"Has image:\", hasimage)\n",
    "print(\"Needs image:\", needsimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hasImage\n",
    "\n",
    "Now I have certainty I'm on a player's biography, I can check for images.\n",
    "\n",
    "I could try and parse the wikitext and see if the tennis player infobox has an image value filled out, but it seems simpler to start with the images API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File:Flag of Finland.svg\n",
      "File:Ambox important.svg\n",
      "File:Baghdatis 2009 Delray 1.jpg\n",
      "File:Flag of France.svg\n",
      "File:Flag of Croatia.svg\n",
      "File:Flag of Argentina.svg\n",
      "File:Flag of Belgium (civil).svg\n",
      "File:Flag of Cyprus.svg\n",
      "File:Commons-logo.svg\n",
      "File:Flag of Chile.svg\n",
      "File:Flag of Russia.svg\n",
      "File:Marcos Baghdatis Serve.JPG\n",
      "File:Flag of Serbia.svg\n",
      "File:Flag of Switzerland.svg\n",
      "File:Flag of the United States.svg\n",
      "File:Marcos Baghdatis 2004 US Open.JPG\n",
      "File:Flag of Thailand.svg\n",
      "File:Flag of the Czech Republic.svg\n",
      "File:Marcos Baghdatis Olympics 2012.jpg\n",
      "File:Marcos Baghdatis2007USOPEN.jpg\n"
     ]
    }
   ],
   "source": [
    "page = site.Pages['Marcos Baghdatis']\n",
    "images = page.images()\n",
    "for image in images:\n",
    "    print(image['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's... a lot of flags. It's because editors like to do this kind of thing:\n",
    "\n",
    "<img src=\"blog/flags.png\" />\n",
    "\n",
    "So to filter them out, what do they have in common?\n",
    "\n",
    "What jumps out at me is that they are SVGs. SVGs are not normally used for photographs (which is what we are trying to detect), so that will be a good start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marcos Baghdatis True\n",
      "Bai Yan False\n",
      "Mirza Ba≈°iƒá False\n"
     ]
    }
   ],
   "source": [
    "def isBoring(imagename):\n",
    "    # Flags, Increase2.svg, Decrease2.svg\n",
    "    return imagename.endswith('.svg')\n",
    "\n",
    "\n",
    "def hasImage(page):\n",
    "    images = page.images()\n",
    "    imgnames = [image['title'] for image in images]\n",
    "    interestingImages = [imgname for imgname in imgnames\n",
    "                         if not isBoring(imgname)]\n",
    "    return bool(interestingImages)\n",
    "\n",
    "\n",
    "for player in['Marcos Baghdatis', 'Bai Yan', 'Mirza Ba≈°iƒá']:\n",
    "    page = getPage(player)\n",
    "    print(player, hasImage(page))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has image: ['Marcos Baghdatis']\n",
      "Disambig: ['Brian Baker']\n",
      "Needs image: ['Bai Yan', 'Mirza Ba≈°iƒá']\n",
      "No page: ['Gregoire Barrere']\n"
     ]
    }
   ],
   "source": [
    "needspage = []\n",
    "disambigs = []\n",
    "hasimage = []\n",
    "needsimage = []\n",
    "\n",
    "with open(PLAYERSFILE) as players:\n",
    "    for player in players:\n",
    "        forwardname = normaliseName(player)\n",
    "        page = getPage(forwardname)\n",
    "        if not page:\n",
    "            needspage.append(forwardname)\n",
    "            continue\n",
    "\n",
    "        if isDisambiguation(page):\n",
    "            disambigs.append(page.name)\n",
    "        elif hasImage(page):\n",
    "            hasimage.append(page.name)\n",
    "        else:\n",
    "            needsimage.append(page.name)\n",
    "            \n",
    "print(\"Has image:\", hasimage)\n",
    "print(\"Disambig:\", disambigs)\n",
    "print(\"Needs image:\", needsimage)\n",
    "print(\"No page:\", needspage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üôå"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full results\n",
    "\n",
    "I modified the above a little bit to print things to file rather than store in a list. You can see the final script at [github](https://github.com/pfctdayelise/aomp/blob/master/script.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (aomp)blaugher@scorpion:~/workspace/aomp$ python script.py \n",
    "    ...............................................................................................\n",
    "    ...............................................................................................\n",
    "    ...............................................................................................\n",
    "    ...............................................................................................\n",
    "    ...............................................................................................\n",
    "    .......................................................................\n",
    "    Has image: 473\n",
    "    See disambigs.txt, needspage.txt and needsimage.txt for further work!\n",
    "    \n",
    "    (aomp)blaugher@scorpion:~/workspace/aomp$ wc -l *txt\n",
    "       25 disambigs.txt\n",
    "       30 needsimage.txt\n",
    "       18 needspage.txt\n",
    "      546 players.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall quite impressive -- only around 5% of the players at the 2016 Australian Open don't have a Wikipedia article, and only another 3% or so need images. (Give or take resolving the name disambiguations and doing a bit more manual verifying that the results seem reasonable.) \n",
    "\n",
    "That leaves some todos:\n",
    "   - Encourage people to [start articles](https://github.com/pfctdayelise/aomp/blob/master/needspage.txt) for the missing players\n",
    "   - Try to resolve [disambiguation pages](https://github.com/pfctdayelise/aomp/blob/master/disambigs.txt) - look for a link on a line that mentions tennis, or even just tennis in the link name\n",
    "   - For [missing photos](https://github.com/pfctdayelise/aomp/blob/master/needsimage.txt), check interwiki links (articles on the same topic in other languages) and see if any of them have images.\n",
    "   - Put together my tennis schedule - seems like I will have a lot of time to enjoy the tennis for itself and not have to worry about photo ops! üéæüéæüéæüéæüéæ\n",
    "\n",
    "_Written by [Brianna Laugher](http://brianna.laugher.id.au) ([@pfctdayelise](https://twitter.com/pfctdayelise)), code is available on [github](https://github.com/pfctdayelise/aomp)._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
